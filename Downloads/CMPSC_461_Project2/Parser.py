import re
from typing import List, Tuple, Any, Union
from ASTNodeDefs import *

# A type alias for clarity, representing parts of expressions
# that can be a full ASTNode or a simple token tuple (like for numbers/identifiers).
ExprType = Union[ASTNode, Tuple[str, Any]]
DataType = str  # e.g., "int" or "hex" or "bool"


class Lexer:
    """
    The Lexer (also known as a tokenizer or scanner) is responsible for breaking
    the raw source code string into a stream of meaningful tokens.
    """

    def __init__(self, code: str) -> None:
        """
        Initializes the Lexer.

        Args:
            code: The source code string to be tokenized.
        """
        self.code = code
        self.tokens: List[Tuple[str, Any]] = []
        # A list of tuples where each tuple contains a token name and a regex pattern.
        # The order is important, as it determines matching priority.
        # TODO: Add new tokens for Project 2 Grammar
        self.token_specs = [
            ("IF", r"if"),
            ("ELSE", r"else"),
            ("FOR", r"for"),
            ("TO", r"to"),
            ("PRINT", r"print"),
            ("AND", r"and"),
            ("OR", r"or"),
            ("NOT", r"not"),
            ("PLUS", r"\+"),
            ("MINUS", r"-"),
            ("MULTIPLY", r"\*"),
            ("DIVIDE", r"/"),
            ("MODULO", r"%"),
            ("EQ", r"=="),
            ("NEQ", r"!="),
            ("GREATER", r">"),
            ("LESS", r"<"),
            ("EQUALS", r"="),
            ("LPAREN", r"\("),
            ("RPAREN", r"\)"),
            ("COMMA", r","),
            ("COLON", r":"),
            ("NUMBER", r"\d+"),
            ("IDENTIFIER", r"[A-Za-z_][A-Za-z0-9_]*"),
            ("SKIP", r"[ \t\n]+"),  # Skips whitespace and newlines
            ("MISMATCH", r"."),  # Catches any other character
        ]
        # A single, combined regex for efficient matching.
        self.token_regex = "|".join(
            f"(?P<{name}>{regex})" for name, regex in self.token_specs
        )

    # TODO: Modify this function as we have new tokens in Project 2 Grammar
    def tokenize(self) -> List[Tuple[str, Any]]:
        """
        Why this function is needed: This is the core of the lexer. Its purpose is to
        transform the raw text-based source code into a structured list of tokens
        that the parser can understand. The parser cannot work with a raw string;
        it needs a sequence of categorized symbols.

        What this function does: It scans the input code from left to right, matching
        the text against the regular expressions defined in `self.token_specs`.
        For each match, it creates a (token_type, value) tuple and adds it to a list.
        It should handle converting numbers to integer types and correctly identifying
        keywords vs. identifiers. It discards meaningless characters like whitespace.
        The process ends when the entire code string is consumed, at which point an
        'EOF' (End of File) token is appended to signify the end of the input.
        """
        for mo in re.finditer(self.token_regex, self.code):
            kind = mo.lastgroup
            value = mo.group()
            if kind == "NUMBER":
                value = int(value)
            elif kind == "SKIP" or kind == "MISMATCH":
                continue
            self.tokens.append((kind, value))
        self.tokens.append(("EOF", None))
        return self.tokens


class Parser:
    """
    The Parser takes the list of tokens generated by the Lexer and builds an
    Abstract Syntax Tree (AST). The AST is a tree representation of the source
    code's structure that is much easier to work with for later stages like
    interpretation or compilation.
    """

    def __init__(self, tokens: List[Tuple[str, Any]]) -> None:
        self.tokens = tokens
        self.pos = 0  # The parser's current position in the token stream
        # Use these to track the variables and their scope
        self.symbol_table = {"global": {}}
        self.scope_counter = 0
        self.scope_stack = ["global"]
        self.messages = []

    def current_token(self) -> Tuple[str, Any]:
        """A helper function to look at the current token without consuming it."""
        return self.tokens[self.pos]

    def advance(self) -> None:
        """A helper function to consume the current token and move to the next one."""
        self.pos += 1

    def expect(self, kind: str) -> Tuple[str, Any]:
        """
        Checks if the current token matches an expected type. If so, it consumes
        the token. If not, it raises a syntax error. This is crucial for
        enforcing the language's grammar rules.
        """
        if self.current_token()[0] == kind:
            token = self.current_token()
            self.advance()
            return token
        else:
            raise SyntaxError(
                f"Expected {kind} but got {self.current_token()[0]} at position {self.pos}"
            )

    def error(self, message: str) -> None:
        self.messages.append(message)

    def parse(self) -> List[ASTNode]:
        """
        Why this function is needed: This is the main entry point for the parsing process.
        It orchestrates the entire parsing operation by repeatedly parsing the fundamental
        unit of our language: a statement.

        What this function does: It creates an empty list to hold the statements of the
        program. It then loops as long as it has not reached the 'EOF' token. In each
        iteration, it calls `parse_statement()` to parse a single statement and appends
        the resulting AST node to the list. Finally, it returns the list of statement
        nodes, which represents the complete program.
        """
        statements = []
        while self.current_token()[0] != "EOF":
            statements.append(self.parse_statement())
        return statements

    # TODO: Modify this function for Project 2
    def parse_statement(self) -> ASTNode:
        """
        Why this function is needed: Our language is composed of different kinds of statements
        (assignments, if-statements, loops, etc.). This function acts as a dispatcher. It needs
        to figure out which kind of statement is next in the token stream and call the
        correct specific function to handle it.

        What this function does: It looks at the type of the `current_token`.
        - If it's an 'IDENTIFIER', it's likely an assignment (e.g., `x = ...`).
        - If it's an 'TYPE', it's likely a declaration, and should call `parse_decl_stmt()`.
        - If it's an 'IF', it calls `parse_if_stmt()`.
        - If it's a 'FOR', it calls `parse_for_stmt()`.
        - If it's a 'PRINT', it calls `parse_print_stmt()`.
        This routing is the essence of a top-down recursive descent parser.
        """
        token_kind = self.current_token()[0]
        if token_kind == "IDENTIFIER":
            return self.parse_assign_stmt()
        elif token_kind == "IF":
            return self.parse_if_stmt()
        elif token_kind == "FOR":
            return self.parse_for_stmt()
        elif token_kind == "PRINT":
            return self.parse_print_stmt()
        else:
            return self.parse_boolean_expression()

    # TODO: Implementation required
    def parse_decl_stmt(self) -> Declaration:
        """
        Why this function is needed: To parse variable declaration statements
        according to the grammar rules.

        What this function does: It consumes a 'TYPE' token followed by an
        'IDENTIFIER' token. It constructs and returns a `Declaration` AST node
        with the type and identifier.
        """
        pass

    # TODO: Modify this function for Project 2
    def parse_assign_stmt(self) -> Assignment:
        """
        Why this function is needed: To parse variable assignment statements
        according to the grammar rules.

        What this function does: It consumes an 'IDENTIFIER' token, an 'EQUALS'
        token, and then calls `parse_expression()` to parse the right-hand side
        expression. It constructs and returns an `Assignment` AST node with the
        identifier and expression.
        """
        identifier = self.expect("IDENTIFIER")
        self.expect("EQUALS")
        expr, _ = self.parse_expression()
        return Assignment(identifier, expr)

    # TODO: Modify this function for Project 2
    def parse_if_stmt(self) -> IfStatement:
        """
        Why this function is needed: To parse the structure of an if-else statement according
        to the grammar rules.

        What this function does: It consumes the 'IF' token, then calls `parse_boolean_expression()`
        to parse the condition. It then expects and consumes a 'COLON', calls `parse_block()`
        to handle the body of the 'then' clause. After that, it checks for an 'ELSE' token to
        handle the optional else part, which also has a colon and a block. It constructs and
        returns an `IfStatement` AST node with the condition, then-block, and optional else-block.
        """
        self.expect("IF")
        condition, _ = self.parse_boolean_expression()
        self.expect("COLON")
        then_block = self.parse_block()
        else_block = None
        if self.current_token()[0] == "ELSE":
            self.advance()
            self.expect("COLON")
            else_block = self.parse_block()
        return IfStatement(condition, then_block, else_block)

    # TODO: Modify this function for Project 2
    def parse_for_stmt(self) -> ForStatement:
        """
        Why this function is needed: To parse the specific syntax of our for-loop.

        What this function does: It consumes tokens in the expected order for a for-loop:
        'FOR', an identifier for the loop variable, 'EQUALS', an expression for the start value,
        'TO', an expression for the end value, and a 'COLON'. Finally, it calls `parse_block()`
        for the loop's body. It bundles all this information into a `ForStatement` AST node.
        """
        self.expect("FOR")
        iterator = self.expect("IDENTIFIER")
        self.expect("EQUALS")
        start_expr, _ = self.parse_expression()
        self.expect("TO")
        end_expr, _ = self.parse_expression()
        self.expect("COLON")
        block = self.parse_block()
        return ForStatement(iterator, start_expr, end_expr, block)

    def parse_print_stmt(self) -> PrintStatement:
        """
        Why this function is needed: To handle the language's built-in print statement.

        What this function does: It consumes the 'PRINT' token and an opening parenthesis 'LPAREN'.
        It then calls `parse_arg_list()` to parse the comma-separated expressions inside the
        parentheses. Finally, it consumes the closing parenthesis 'RPAREN' and returns a
        `PrintStatement` AST node containing the list of arguments.
        """
        self.expect("PRINT")
        self.expect("LPAREN")
        args = []
        if self.current_token()[0] != "RPAREN":
            args = self.parse_arg_list()
        self.expect("RPAREN")
        return PrintStatement(args)

    def parse_block(self) -> Block:
        """
        Why this function is needed: Control flow statements like 'if' and 'for' need to execute
        a sequence of other statements. A 'block' represents this sequence.

        What this function does: It creates a list to hold statements. It then repeatedly calls
        `parse_statement()` to parse all statements until it reaches a token that signals the end
        of the block. It returns a `Block` AST node containing the list of parsed statements.
        """
        statements = []
        while self.current_token()[0] not in ("ELSE", "ENDIF", "ENDFOR", "EOF"):
            statements.append(self.parse_statement())
        return Block(statements)

    def parse_arg_list(self) -> List[ExprType]:
        """
        Why this function is needed: To handle comma-separated lists of values, such as in the
        print statement.

        What this function does: It first parses one expression. Then, it enters a loop that
        continues as long as the current token is a 'COMMA'. Inside the loop, it consumes the
        comma and parses the next expression. It returns a list of all the parsed expression nodes.
        """
        first, _ = self.parse_expression()
        args = [first]
        while self.current_token()[0] == "COMMA":
            self.advance()
            expr, _ = self.parse_expression()
            args.append(expr)
        return args

    # TODO: Modify this function for Project 2
    def parse_boolean_expression(self) -> Tuple[ExprType, DataType]:
        """
        Why this function is needed: This function handles the logical 'OR' operator. To correctly
        implement operator precedence, we need a separate function for each level of precedence.
        'OR' has the lowest precedence among logical operators.

        What this function does: It first calls `parse_boolean_term()` to get the left-hand side.
        Then, it loops as long as it sees an 'OR' token. In the loop, it creates a `LogicalOperation`
        node with the left side, the 'OR' operator, and the result of parsing the right side.
        This left-associative structure correctly handles chains like `A or B or C`.
        """
        node, _ = self.parse_boolean_term()
        while self.current_token()[0] == "OR":
            op = self.current_token()
            self.advance()
            right, _ = self.parse_boolean_term()
            node = LogicalOperation(node, op, right)
        return node, ""

    # TODO: Modify this function for Project 2
    def parse_boolean_term(self) -> Tuple[ExprType, DataType]:
        """
        Why this function is needed: This handles the 'AND' operator, which has a higher
        precedence than 'OR'.

        What this function does: Its structure is identical to `parse_boolean_expression`, but
        it deals with the 'AND' operator and calls `parse_boolean_factor()` for its operands.
        This ensures that expressions like `A and B or C` are parsed as `(A and B) or C`.
        """
        node, _ = self.parse_boolean_factor()
        while self.current_token()[0] == "AND":
            op = self.current_token()
            self.advance()
            right, _ = self.parse_boolean_factor()
            node = LogicalOperation(node, op, right)
        return node, ""

    # TODO: Modify this function for Project 2
    def parse_boolean_factor(self) -> Tuple[ExprType, DataType]:
        """
        Why this function is needed: This handles the unary 'NOT' operator, which has the
        highest logical precedence.

        What this function does: It checks for a 'NOT' token. If found, it consumes it,
        recursively calls `parse_boolean_factor()` to parse the expression being negated, and
        wraps it in a `UnaryOperation` node. If there is no 'NOT', it simply calls the next
        level of the precedence hierarchy, `parse_comparison()`.
        """
        token = self.current_token()
        if token[0] == "NOT":
            self.advance()
            factor, _ = self.parse_boolean_factor()
            return UnaryOperation(token, factor), ""
        return self.parse_comparison()

    # TODO: Modify this function for Project 2
    def parse_comparison(self) -> Tuple[ExprType, DataType]:
        """
        Why this function is needed: To parse comparison expressions like `a > b` or `x == 10`.

        What this function does: It first calls `parse_expression()` to get the left-hand side
        (an arithmetic expression). It then checks if the current token is a comparison
        operator ('==', '!=', '>', '<'). If so, it consumes the operator and calls
        `parse_expression()` again for the right-hand side, creating a `BinaryOperation` node.
        If not, it just returns the left-hand side node it already parsed.
        """
        while self.current_token()[0] in ("EQ", "NEQ", "LESS", "GREATER"):
            op = self.current_token()
            self.advance()
            right, _ = self.parse_expression()
            node = BinaryOperation(node, op, right)
        return node, ""

    # TODO: Modify this function for Project 2
    def parse_expression(self) -> Tuple[ExprType, DataType]:
        """
        Why this function is needed: To handle the lowest precedence arithmetic operators:
        addition ('+') and subtraction ('-').

        What this function does: Following the same pattern as the boolean functions, it first
        calls `parse_term()` to get a higher-precedence operand. It then loops as long as it
        sees a 'PLUS' or 'MINUS' token, building `BinaryOperation` nodes in a left-associative way.
        """
        node, _ = self.parse_term()
        while self.current_token()[0] in ("PLUS", "MINUS"):
            op = self.current_token()
            self.advance()
            right, _ = self.parse_term()
            node = BinaryOperation(node, op, right)
        return node, ""

    # TODO: Modify this function for Project 2
    def parse_term(self) -> Tuple[ExprType, DataType]:
        """
        Why this function is needed: To handle multiplication ('*'), division ('/'), and modulo ('%'),
        which have higher precedence than addition and subtraction.

        What this function does: It calls `parse_factor()` to get its operands and loops on
        '*', '/', and '%' operators. This ensures that `a + b * c` is correctly parsed as `a + (b * c)`.
        """
        node, _ = self.parse_factor()
        while self.current_token()[0] in ("MULTIPLY", "DIVIDE", "MODULO"):
            op = self.current_token()
            self.advance()
            right, _ = self.parse_factor()
            node = BinaryOperation(node, op, right)
        return node, ""

    # TODO: Modify this function for Project 2
    def parse_factor(self) -> Tuple[ExprType, DataType]:
        """
        Why this function is needed: To handle unary plus and minus operators (e.g., `-5`).
        These have higher precedence than multiplication.

        What this function does: It checks for a 'PLUS' or 'MINUS' token. If found, it consumes it,
        recursively calls `parse_factor()` for the operand, and returns a `UnaryOperation` node.
        If not, it calls `parse_primary()` for the highest-precedence elements.
        """
        token = self.current_token()
        if token[0] in ("PLUS", "MINUS"):
            self.advance()
            factor, _ = self.parse_factor()
            return UnaryOperation(token, factor), ""
        return self.parse_primary()

    # TODO: Modify this function for Project 2
    def parse_primary(self) -> Tuple[ExprType, DataType]:
        """
        Why this function is needed: This function is at the bottom of the expression parsing
        hierarchy. It handles the most basic, highest-precedence elements of expressions. These
        are the "atoms" of an expression.
        """
        token = self.current_token()
        if token[0] == "NUMBER":
            self.advance()
            return token, ""
        elif token[0] == "IDENTIFIER":
            self.advance()
            return token, ""
        elif token[0] == "LPAREN":
            self.advance()
            node, _ = self.parse_boolean_expression()
            self.expect("RPAREN")
            return node, ""
        else:
            raise SyntaxError(f"Invalid syntax for primary expression at {token}")

    # TODO: Implement logic to enter a new scope, add it to symbol table, and update `scope_stack`
    def enter_scope(self) -> None:
        pass

    # TODO: Implement logic to exit the current scope, removing it from `scope_stack`
    def exit_scope(self) -> None:
        pass

    # TODO: Implementation required
    def checkVarRedeclared(self, identifier: str) -> bool:
        """
        Check if variable has already been declared in the current scope or any enclosing scopes
        This function should be called in parse_decl_stmt
        Return True and write error message if already declared in current scope, False otherwise
        """
        pass

    # DO NOT CHANGE THIS FUNCTION
    def checkVarRedeclaredErrorMsg(self, identifier: str) -> None:
        """
        It writes error message to self.messages
        This function should be called in checkVarRedeclared
        The autograder will check error message in this format
        """
        self.error(
            f"Variable {identifier} has already been declared in the current scope\n"
        )

    # TODO: Implementation required
    def checkVarDeclared(self, identifier: str) -> None:
        """
        Check if variable is declared in the current scope or any enclosing scopes before use
        This function should be called when an identifier is used
        Return True if declared, False and write error message otherwise
        """
        pass

    # DO NOT CHANGE THIS FUNCTION
    def checkVarDeclaredErrorMsg(self, identifier: str) -> None:
        """
        It writes error message to self.messages
        This function should be called in checkVarDeclared
        The autograder will check error message in this format
        """
        self.error(
            f"Variable {identifier} has not been declared in the current or any enclosing scopes\n"
        )

    # DO NOT CHANGE THIS FUNCTION
    # USE THIS FUNCTION WHEN RULE 1 OR RULE 5 IS VIOLATED
    def checkBoolOpErrorMsg(self) -> None:
        """
        It writes error message to self.messages
        This function should be called when a non-boolean expression is used in a boolean operation or if condition
        """
        self.error(
            f"Non-boolean expression used in boolean operation or if condition\n"
        )

    # DO NOT CHANGE THIS FUNCTION
    # USE THIS FUNCTION WHEN RULE 2 IS VIOLATED (ARITH ONLY ACCEPTS INT OR HEX)
    def checkArithOpErrorMsg(self) -> None:
        """
        It writes error message to self.messages
        This function should be called when a non-integer expression is used in an arithmetic operation
        """
        self.error(f"Invalid input types in arithmetic operation\n")

    # DO NOT CHANGE THIS FUNCTION
    # USE THIS FUNCTION WHEN RULE 2 OR RULE 3 IS VIOLATED (COMPARISON AND ARITH TYPE MISMATCH)
    def checkTypeMatchErrorMsg(self, type1: str, type2: str) -> None:
        """
        It writes error message to self.messages
        This function should be called when type mismatch is detected
        """
        self.error(f"Type mismatch detected between {type1} and {type2}\n")

    # DO NOT CHANGE THIS FUNCTION
    # USE THIS FUNCTION WHEN RULE 4 IS VIOLATED
    def checkAssignErrorMsg(
        self, identifier: str, var_type: str, expr_type: str
    ) -> None:
        """
        It writes error message to self.messages
        This function should be called when type mismatch is detected in assignment
        """
        self.error(
            f"Type mismatch detected in assignment to variable {identifier} of type {var_type} with expression of type {expr_type}\n"
        )

    # TODO: Implement logic to add a variable to the current scope in `symbol_table`
    def add_variable(self, name: str, var_type: str) -> None:
        pass

    # TODO: Retrieve the variable type from `symbol_table` if it exists
    def get_variable_type(self, name: str) -> str:
        pass
